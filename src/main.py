import sys
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Dict, Any, Optional

from .cli.arguments import create_parser, validate_args
from .pdf.extractor import PDFExtractor
from .pdf.images import ImageExtractor
from .llm.summarize import Summarizer
from .utils.files import format_bytes, ensure_directory


def setup_logging(verbose: bool = False, quiet: bool = False, log_to_file: bool = True) -> None:
    """
    Configura o sistema de logging da aplica√ß√£o com suporte a arquivo e console.
    
    Args:
        verbose: Se True, exibe logs DEBUG
        quiet: Se True, exibe apenas logs ERROR
        log_to_file: Se True, salva logs em arquivo com rota√ß√£o
    """
    if quiet:
        log_level = logging.ERROR
    elif verbose:
        log_level = logging.DEBUG
    else:
        log_level = logging.INFO
    
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    handlers = []
    
    console_handler = logging.StreamHandler()
    console_handler.setLevel(log_level)
    console_handler.setFormatter(logging.Formatter(log_format, date_format))
    handlers.append(console_handler)
    
    if log_to_file:
        try:
            log_dir = ensure_directory('logs')
            log_file = log_dir / 'pdf_analyzer.log'
            
            file_handler = RotatingFileHandler(
                log_file,
                maxBytes=5 * 1024 * 1024,
                backupCount=3,
                encoding='utf-8'
            )
            file_handler.setLevel(logging.DEBUG)
            file_handler.setFormatter(logging.Formatter(log_format, date_format))
            handlers.append(file_handler)
        except Exception as error:
            print(f"Aviso: N√£o foi poss√≠vel configurar log em arquivo: {error}")
    
    logging.basicConfig(
        level=log_level,
        format=log_format,
        datefmt=date_format,
        handlers=handlers
    )


def print_analysis_results(pdf_analysis: Dict[str, Any]) -> None:
    """
    Exibe os resultados da an√°lise do PDF na sa√≠da padr√£o.
    
    Args:
        pdf_analysis: Dicion√°rio contendo os resultados da an√°lise
    """
    SEPARATOR = "=" * 70
    
    print(f"\n{SEPARATOR}")
    print("AN√ÅLISE DO PDF")
    print(SEPARATOR)
    print(f"\nArquivo: {pdf_analysis['file_name']}")
    print(f"Caminho: {pdf_analysis['file_path']}")
    print(f"\nüìÑ N√∫mero de p√°ginas: {pdf_analysis['page_count']}")
    print(f"üì¶ Tamanho do arquivo: {format_bytes(pdf_analysis['file_size_bytes'])} ({pdf_analysis['file_size_bytes']:,} bytes)")
    print(f"üìù Total de palavras: {pdf_analysis['word_count']:,}")
    print(f"üìö Tamanho do vocabul√°rio: {pdf_analysis['vocabulary_size']:,} palavras distintas")
    
    print(f"\nüî§ 10 palavras mais comuns (sem stopwords):")
    for position, (word, frequency) in enumerate(pdf_analysis['most_common_words'], start=1):
        print(f"   {position:2}. {word:<20} ({frequency:,} ocorr√™ncias)")
    
    print()


def print_image_results(extracted_images: list, output_directory: str) -> None:
    """
    Exibe os resultados da extra√ß√£o de imagens.
    
    Args:
        extracted_images: Lista de caminhos das imagens extra√≠das
        output_directory: Diret√≥rio onde as imagens foram salvas
    """
    SEPARATOR = "=" * 70
    MAX_IMAGES_TO_SHOW = 5
    
    print(SEPARATOR)
    print("EXTRA√á√ÉO DE IMAGENS")
    print(SEPARATOR)
    print(f"\nüñºÔ∏è  Total de imagens extra√≠das: {len(extracted_images)}")
    
    if extracted_images:
        print(f"üìÅ Diret√≥rio de sa√≠da: {output_directory}")
        print(f"\nPrimeiras imagens:")
        
        for image_path in extracted_images[:MAX_IMAGES_TO_SHOW]:
            print(f"   - {Path(image_path).name}")
        
        remaining_images = len(extracted_images) - MAX_IMAGES_TO_SHOW
        if remaining_images > 0:
            print(f"   ... e mais {remaining_images} imagens")
    
    print()


def print_summary(summary_text: str) -> None:
    """
    Exibe o resumo gerado pelo modelo LLM.
    
    Args:
        summary_text: Texto do resumo gerado
    """
    SEPARATOR = "=" * 70
    
    print(SEPARATOR)
    print("RESUMO DO DOCUMENTO (gerado por LLM)")
    print(SEPARATOR)
    print(f"\n{summary_text}\n")


def generate_markdown_report(
    pdf_analysis: Dict[str, Any],
    extracted_images: list,
    summary_text: Optional[str],
    report_output_path: str
) -> None:
    """
    Gera relat√≥rio completo em formato Markdown.
    
    Args:
        pdf_analysis: Resultados da an√°lise do PDF
        extracted_images: Lista de imagens extra√≠das
        summary_text: Resumo gerado (ou None se desabilitado)
        report_output_path: Caminho onde salvar o relat√≥rio
    """
    logger = logging.getLogger(__name__)
    logger.info(f"Gerando relat√≥rio Markdown: {report_output_path}")
    
    with open(report_output_path, 'w', encoding='utf-8') as report_file:
        report_file.write("# Relat√≥rio de An√°lise de PDF\n\n")
        
        report_file.write("## üìÑ Informa√ß√µes do Documento\n\n")
        report_file.write(f"- **Arquivo**: `{pdf_analysis['file_name']}`\n")
        report_file.write(f"- **Caminho**: `{pdf_analysis['file_path']}`\n")
        report_file.write(f"- **N√∫mero de p√°ginas**: {pdf_analysis['page_count']}\n")
        report_file.write(f"- **Tamanho**: {format_bytes(pdf_analysis['file_size_bytes'])} ({pdf_analysis['file_size_bytes']:,} bytes)\n")
        report_file.write(f"- **Total de palavras**: {pdf_analysis['word_count']:,}\n")
        report_file.write(f"- **Vocabul√°rio**: {pdf_analysis['vocabulary_size']:,} palavras distintas\n\n")
        
        report_file.write("## üî§ Palavras Mais Comuns\n\n")
        report_file.write("| # | Palavra | Frequ√™ncia |\n")
        report_file.write("|---|---------|------------|\n")
        for position, (word, frequency) in enumerate(pdf_analysis['most_common_words'], start=1):
            report_file.write(f"| {position} | {word} | {frequency:,} |\n")
        report_file.write("\n")
        
        report_file.write("## üñºÔ∏è Imagens Extra√≠das\n\n")
        report_file.write(f"**Total**: {len(extracted_images)} imagens\n\n")
        if extracted_images:
            report_file.write("### Lista de Imagens\n\n")
            for image_path in extracted_images:
                report_file.write(f"- `{Path(image_path).name}`\n")
            report_file.write("\n")
        
        if summary_text:
            report_file.write("## üìù Resumo do Documento\n\n")
            report_file.write(f"{summary_text}\n\n")
        
        report_file.write("---\n")
        report_file.write("*Relat√≥rio gerado pela ferramenta CLI de An√°lise de PDF*\n")
    
    logger.info(f"Relat√≥rio salvo em: {report_output_path}")


def main() -> int:
    parser = create_parser()
    args = parser.parse_args()
    
    if not validate_args(args):
        return 1
    
    setup_logging(verbose=args.verbose, quiet=args.quiet)
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("Iniciando an√°lise do PDF...")
        with PDFExtractor(args.pdf_file) as extractor:
            analysis = extractor.analyze()
        
        print_analysis_results(analysis)
        
        image_paths = []
        if not args.no_images:
            logger.info("Iniciando extra√ß√£o de imagens...")
            with ImageExtractor(args.pdf_file) as img_extractor:
                output_dir = args.output_dir or f"imagens/{Path(args.pdf_file).stem}"
                image_paths = img_extractor.extract_images(output_dir)
            
            print_image_results(image_paths, output_dir)
        
        summary = None
        if not args.no_summary:
            logger.info("Iniciando gera√ß√£o de resumo com LLM...")
            print("="*70)
            print("Gerando resumo com modelo de linguagem...")
            print("(Isso pode levar alguns minutos na primeira execu√ß√£o)")
            print("="*70 + "\n")
            
            summarizer = Summarizer(model_name=args.model)
            summary = summarizer.summarize(analysis['full_text'])
            summarizer.cleanup()
            
            print_summary(summary)
        
        if args.report:
            generate_markdown_report(analysis, image_paths, summary, args.report)
            print(f"üìã Relat√≥rio Markdown salvo em: {args.report}\n")
        
        print("="*70)
        print("‚úÖ Processamento conclu√≠do com sucesso!")
        print("="*70 + "\n")
        
        return 0
    
    except FileNotFoundError as e:
        logger.error(f"Arquivo n√£o encontrado: {e}")
        print(f"\n‚ùå Erro: {e}\n")
        return 1
    
    except Exception as e:
        logger.error(f"Erro durante o processamento: {e}", exc_info=True)
        print(f"\n‚ùå Erro: {e}\n")
        return 1


if __name__ == '__main__':
    sys.exit(main())
